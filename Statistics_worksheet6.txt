1. B
2. C
3. A
4. A
5. C
6. B
7. B
8. D
9. A
10. Bayes theorem provides a way to calculate the probability of a hypothesis based on its prior probability, the probabilities of observing various data given the hypothesis, and the observed data itself.In practice, it is very challenging to calculate full Bayes Theorem for classification.The priors for the class and the data are easy to estimate from a training dataset, if the dataset is suitability representative of the broader problem.
The conditional probability of the observation based on the class is not feasible unless the number of examples is extraordinarily large, e.g. large enough to effectively estimate the probability distribution for all different possible combinations of values. This is almost never the case, we will not have sufficient coverage of the domain.As such, the direct application of Bayes Theorem also becomes intractable, especially as the number of variables or features increases.

11. Zscore is also known as a standard score, because it allows comparison of scores on different kinds of variables by standardizing the distribution. A standard normal distribution is a normally shaped distribution with a mean of 0 and a standard deviation of 1.The value of the z-score tells you how many standard deviations you are away from the mean. If a z-score is equal to 0, it is on the mean.
A positive z-score indicates the raw score is higher than the mean average. For example, if a z-score is equal to +1, it is 1 standard deviation above the mean.
A negative z-score reveals the raw score is below the mean average. For example, if a z-score is equal to -2, it is 2 standard deviations below the mean.

12. A t-test is a statistical test that is used to compare the means of two groups. It is often used in hypothesis testing to determine whether a process or treatment actually has an effect on the population of interest, or whether two groups are different from one another.

13. In statistics, a percentile is a type of quantile which divides the given probability distribution or sample into 100 equal sized intervals, this allows the data to be analyzed in terms of percentages

14. Analysis of variance (ANOVA) is an analysis tool used in statistics that splits an observed aggregate variability found inside a data set into two parts: systematic factors and random factors. The systematic factors have a statistical influence on the given data set, while the random factors do not. Analysts use the ANOVA test to determine the influence that independent variables have on the dependent variable in a regression study.

15. The one-way ANOVA is used to determine whether there are any statistically significant differences between the means of two or more independent groups. For example, you could use a one-way ANOVA to understand whether exam performance differed based on test anxiety levels amongst students, dividing students into three independent groups i.e, low, medium and high-stressed students. ANOVA test cannot tell you which specific groups were statistically significantly different from each other, it only tells you that at least two groups were different. Since you may have three, four, five or more groups in your study design, determining which of these groups differ from each other is important.